{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ba65e3-f3bb-4b56-8872-c4ad3ff8cf4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4707758-c9c9-4260-80fa-cfe5d9d47f01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv transformers==4.38.1\n",
    "# !pip install -Iv datasets==2.1.0\n",
    "# !pip install -Iv tensorflow==2.15.0\n",
    "# !pip install -Iv keras==3.0.5\n",
    "# !pip install tf-keras\n",
    "# !pip install -Iv nltk==3.2.4\n",
    "# !pip install -Iv contractions==0.1.73\n",
    "# !pip install -Iv accelerate==0.27.2\n",
    "# !pip install -Iv scikit-learn==1.4.0\n",
    "\n",
    "# !pip install datasets --upgrade\n",
    "# !pip install nltk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758e973f-ccfb-4a53-ab93-a01784b8cfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 05:54:54.236928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, load_dataset, load_metric\n",
    "import datasets\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding, DistilBertConfig, DistilBertForSequenceClassification, BertConfig, BertForSequenceClassification, create_optimizer, TrainingArguments, Trainer\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import pipeline\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e15d91-ef49-4c15-935c-076bf7ca698f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8751bfa4-2c0b-4241-8bb8-b97279565749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = 'data/train.csv'\n",
    "test_data_path = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe48ba27-0e35-4662-9775-060001a02db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILL NEVER COME BACK! HORRIBLE SERVICE &amp; NASTY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible food.  Terrible service.\\n\\nThe absol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So, right away if I go into a buffet setting, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have gotten good cuts from this place. I eve...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I felt this place was a bit lackluster conside...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  WILL NEVER COME BACK! HORRIBLE SERVICE & NASTY...      1\n",
       "1  Terrible food.  Terrible service.\\n\\nThe absol...      1\n",
       "2  So, right away if I go into a buffet setting, ...      2\n",
       "3  I have gotten good cuts from this place. I eve...      3\n",
       "4  I felt this place was a bit lackluster conside...      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data = pd.read_csv(train_data_path)\n",
    "labelled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5220cd1d-8170-4f0e-b85e-f852a0c50f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelled_data['stars'] = labelled_data['stars'].replace({1: 'one_star', 2: 'two_stars', 3: 'three_stars'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdd68cf-a963-4152-afb1-94e59f797be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILL NEVER COME BACK! HORRIBLE SERVICE &amp; NASTY...</td>\n",
       "      <td>one_star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible food.  Terrible service.\\n\\nThe absol...</td>\n",
       "      <td>one_star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So, right away if I go into a buffet setting, ...</td>\n",
       "      <td>two_stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have gotten good cuts from this place. I eve...</td>\n",
       "      <td>three_stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I felt this place was a bit lackluster conside...</td>\n",
       "      <td>two_stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        stars\n",
       "0  WILL NEVER COME BACK! HORRIBLE SERVICE & NASTY...     one_star\n",
       "1  Terrible food.  Terrible service.\\n\\nThe absol...     one_star\n",
       "2  So, right away if I go into a buffet setting, ...    two_stars\n",
       "3  I have gotten good cuts from this place. I eve...  three_stars\n",
       "4  I felt this place was a bit lackluster conside...    two_stars"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb96955-9796-4242-b63d-bf773d3a56c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116bdd58-7a02-498b-bee2-289e7c4a32cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>one_star</th>\n",
       "      <th>three_stars</th>\n",
       "      <th>two_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILL NEVER COME BACK! HORRIBLE SERVICE &amp; NASTY...</td>\n",
       "      <td>one_star</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible food.  Terrible service.\\n\\nThe absol...</td>\n",
       "      <td>one_star</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So, right away if I go into a buffet setting, ...</td>\n",
       "      <td>two_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have gotten good cuts from this place. I eve...</td>\n",
       "      <td>three_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I felt this place was a bit lackluster conside...</td>\n",
       "      <td>two_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Back when I lived in Pollock Halls in my first...</td>\n",
       "      <td>three_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Short version:\\n- 20 stars for having free vod...</td>\n",
       "      <td>two_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Okay.....read the other reviews about taking t...</td>\n",
       "      <td>one_star</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The food is really good, but we had one big co...</td>\n",
       "      <td>three_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cool place, comfortable. Sorely needed in the ...</td>\n",
       "      <td>three_stars</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        stars  one_star  \\\n",
       "0  WILL NEVER COME BACK! HORRIBLE SERVICE & NASTY...     one_star      True   \n",
       "1  Terrible food.  Terrible service.\\n\\nThe absol...     one_star      True   \n",
       "2  So, right away if I go into a buffet setting, ...    two_stars     False   \n",
       "3  I have gotten good cuts from this place. I eve...  three_stars     False   \n",
       "4  I felt this place was a bit lackluster conside...    two_stars     False   \n",
       "5  Back when I lived in Pollock Halls in my first...  three_stars     False   \n",
       "6  Short version:\\n- 20 stars for having free vod...    two_stars     False   \n",
       "7  Okay.....read the other reviews about taking t...     one_star      True   \n",
       "8  The food is really good, but we had one big co...  three_stars     False   \n",
       "9  Cool place, comfortable. Sorely needed in the ...  three_stars     False   \n",
       "\n",
       "   three_stars  two_stars  \n",
       "0        False      False  \n",
       "1        False      False  \n",
       "2        False       True  \n",
       "3         True      False  \n",
       "4        False       True  \n",
       "5         True      False  \n",
       "6        False       True  \n",
       "7        False      False  \n",
       "8         True      False  \n",
       "9         True      False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode the labels \n",
    "one_hot_labels = pd.get_dummies(labelled_data['stars'])\n",
    "# # drop the old 'stars' column to replace with the one hot encoded values \n",
    "# labelled_data = labelled_data.drop('stars', axis= 1)\n",
    "# join with the one hot encoded \n",
    "labelled_data = labelled_data.join(one_hot_labels)\n",
    "\n",
    "labelled_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635b2c15-b336-4f75-b7ca-ad54e3cae706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 1. Expand Contractions using contractions library\n",
    "# def expand_contractions(text):\n",
    "#     return contractions.fix(text)\n",
    "\n",
    "# # Apply expand_contractions function to 'text' column\n",
    "# labelled_data['text'] = labelled_data['text'].apply(expand_contractions)\n",
    "\n",
    "# # 2. Lower Case\n",
    "# labelled_data['text'] = labelled_data['text'].str.lower()\n",
    "\n",
    "# # 3. Remove Punctuations\n",
    "# PUNCT_TO_REMOVE = string.punctuation\n",
    "# def remove_punctuation(text):\n",
    "#     \"\"\"custom function to remove the punctuation\"\"\"\n",
    "#     return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda text: remove_punctuation(text))\n",
    "\n",
    "# # 4. Remove Extra Spaces\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda x: re.sub(' +', ' ', x.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d3075a-a13b-4f3b-b235-e46a7fb37aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download the WordNet resource\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870227d5-4752-4a64-b8af-575cdb0d7ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 5. Remove Stopwords\n",
    "# STOPWORDS = set(stopwords.words('english'))\n",
    "# def remove_stopwords(text):\n",
    "#     \"\"\"custom function to remove the stopwords\"\"\"\n",
    "#     return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb937415-a715-46b8-891e-dfa040bf22dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download the WordNet resource\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56e743eb-301c-4d39-ad4b-5f308fe22fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip /home/ec2-user/nltk_data/corpora/wordnet.zip -d /home/ec2-user/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "261ab0ae-371b-44ee-8693-5364e797e647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 6. Stemming and Lemmatization\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# def lemmatize_words(text):\n",
    "#     return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f803d682-0f1d-44e9-a6bb-78356e51285c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labelled_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35d50d-9fc7-4c8e-9a9f-7eb4dba25589",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01886e06-9be0-4441-a338-c2d953c65e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    labelled_data['text'], \n",
    "    labelled_data[['one_star', 'two_stars', 'three_stars']], \n",
    "    test_size= 0.2, \n",
    "    random_state= 42, \n",
    "    stratify= labelled_data['stars']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13cff12f-028b-4840-90e1-fd090ca82fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_star  two_stars  three_stars\n",
      "False     False      True           1600\n",
      "          True       False          1600\n",
      "True      False      False          1600\n",
      "Name: count, dtype: int64\n",
      "one_star  two_stars  three_stars\n",
      "False     False      True           400\n",
      "          True       False          400\n",
      "True      False      False          400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_valid.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2369ed47-2ac0-472b-a568-ca868d9b255d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1882e3a4-17f7-4151-88f9-0c4559823309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0463147-4173-42ee-b13e-81491c1f0e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "train_ind = X_train.index.values.tolist()\n",
    "valid_ind = X_valid.index.values.tolist()\n",
    "\n",
    "train_data = {'text': [], 'one_star': [], 'two_stars': [], 'three_stars': []}\n",
    "valid_data = {'text': [], 'one_star': [], 'two_stars': [], 'three_stars': []}\n",
    "\n",
    "for ti in train_ind:\n",
    "    train_data['text'].append(X_train[ti])\n",
    "    train_data['one_star'].append(y_train.loc[ti]['one_star'])\n",
    "    train_data['two_stars'].append(y_train.loc[ti]['two_stars'])\n",
    "    train_data['three_stars'].append(y_train.loc[ti]['three_stars'])\n",
    "\n",
    "for vi in valid_ind:\n",
    "    valid_data['text'].append(X_valid[vi])\n",
    "    valid_data['one_star'].append(y_valid.loc[vi]['one_star'])\n",
    "    valid_data['two_stars'].append(y_valid.loc[vi]['two_stars'])\n",
    "    valid_data['three_stars'].append(y_valid.loc[vi]['three_stars'])\n",
    "    \n",
    "print(len(train_data['text']))\n",
    "print(len(valid_data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "821db20f-0478-4d9f-8acb-cfc838adf6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(train_data)\n",
    "valid_dataset = Dataset.from_dict(valid_data)\n",
    "data = datasets.DatasetDict({\"train\": train_dataset,\"valid\": valid_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0601ffdd-49af-4e7a-8c60-dabdcd91b7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'one_star', 'two_stars', 'three_stars'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'one_star', 'two_stars', 'three_stars'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85de4c8d-0fe5-4e70-893a-c491e05815b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Remeber ten years ago, when Wired was publishing articles about how the Internet would end retail shopping?  Well, they were wrong.  Bad customer service will end retail shopping and this Best Buy is a fine example of the downward trend.  The people that work at this ubiquitous big box store are assholes that usually don't know anything about their products and could give two fucks about whether or not you're being helped.    \\\\r\\\\n\\\\r\\\\nThat said, man, do I love gadgets.  And Best Buy's got a lot of 'em.\",\n",
       " 'one_star': False,\n",
       " 'two_stars': True,\n",
       " 'three_stars': False}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afbff5ac-4622-4930-8a74-c6c170ea3c85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one_star', 'two_stars', 'three_stars']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label for label in data['train'].features.keys() if label not in ['text']]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1cb89db-2f79-4127-8f02-d64b58c3226a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'one_star', 1: 'two_stars', 2: 'three_stars'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b994731-ad04-453c-a258-2c1bee196655",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aa05bba-430c-4cb9-b93f-d0a23f4bd48c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def preprocess_data(examples):\n",
    "  # take a batch of texts\n",
    "  text = examples[\"text\"]\n",
    "  # encode them\n",
    "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "  # add labels\n",
    "  labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "  # create numpy array of shape (batch_size, num_labels)\n",
    "  labels_matrix = np.zeros((len(text), len(labels)))\n",
    "  # fill numpy array\n",
    "  for idx, label in enumerate(labels):\n",
    "    labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "  encoding[\"labels\"] = labels_matrix.tolist()\n",
    "  \n",
    "  return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "445d7735-b1b0-4d61-a666-c55f816f20d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201ae270a6dc4a7c8580865dabfb6134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897288400cd14b1cb2d0fd9d963e8d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = data.map(preprocess_data, batched=True, remove_columns= data['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36d745c4-5223-40ed-80fb-d6d2a73f7ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7faa7e-1f8a-4faf-b1ec-d80204005f18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data['train'][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad602c24-ebfe-4f39-8030-0ef1f8695bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_data.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83c00b-3afe-40c9-9222-13c413a0aaad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80ccc166-6765-42b8-90dc-e3b67232407a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9ee71-459f-4653-a2b1-c9377ab2eb9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd9be9bd-1cc2-45ae-833e-b02d6040b332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", \n",
    "                                                           problem_type=\"multi_label_classification\", \n",
    "                                                           num_labels=len(labels),\n",
    "                                                           id2label=id2label,\n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7f671-413a-4afe-937d-ddcfc90cfa9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train Model Pt.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efd53ef9-3a92-4a4b-b7f4-a733c4dbade6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24fe3076-1618-49ef-a181-502ce90d83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    for i, row in enumerate(probs): \n",
    "        y_pred[i, np.argmax(row.detach().numpy())] = 1 \n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    # f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    # roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    # metrics = {'f1': f1_micro_average,\n",
    "    #            'roc_auc': roc_auc,\n",
    "    #            'accuracy': accuracy}\n",
    "    metrics = {'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, \n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds, \n",
    "        labels=p.label_ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7faef-ed2c-4a31-82cc-0f75f1bf3e9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Verify a batch and forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39c23668-d6ca-4ba0-b54b-fcd2eaee7ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data['train'][0]['labels'].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1eff2ab-f1a7-48e8-b63f-5aeb4af62970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 31157,   242,  1943,  2724,   107,   536,     6,    77, 36572,\n",
       "           21, 10467,  7201,    59,   141,     5,  3742,    74,   253,  2304,\n",
       "         3482,   116,  1437,  2647,     6,    51,    58,  1593,     4,  1437,\n",
       "         5654,  2111,   544,    40,   253,  2304,  3482,     8,    42,  2700,\n",
       "         4228,    16,    10,  2051,  1246,     9,     5, 14659,  2904,     4,\n",
       "         1437,    20,    82,    14,   173,    23,    42, 25107,   380,  2233,\n",
       "         1400,    32,  8446, 31670,    14,  2333,   218,    75,   216,   932,\n",
       "           59,    49,   785,     8,   115,   492,    80,   856, 19667,    59,\n",
       "          549,    50,    45,    47,   214,   145,  1147,     4,  1437,  1437,\n",
       "         1437, 44128,   338, 37457,   282, 37457,   338, 37457,   282,  1711,\n",
       "           26,     6,   313,     6,   109,    38,   657, 21485,     4,  1437,\n",
       "          178,  2700,  4228,    18,   300,    10,   319,     9,   128,   991,\n",
       "            4,     2,     1,     1,     1,     1,     1,     1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data['train']['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d1c9388-bd66-4cb6-b38d-e9b40d9c2d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7314, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.0314, -0.2000, -0.0119]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass\n",
    "outputs = model(input_ids=tokenized_data['train']['input_ids'][0].unsqueeze(0), labels=tokenized_data['train'][0]['labels'].unsqueeze(0))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8f1a2-02f1-4f94-9738-6457a4b8fe71",
   "metadata": {},
   "source": [
    "# # Train Model Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e774d9cb-5d67-417f-92fb-3c868435ffc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "metric_name = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70132ca4-4734-460d-8fb6-c55de90f40a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"roberto-round-1\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5, # 2e-5\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    # weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    warmup_steps= 100,\n",
    "    lr_scheduler_type= 'constant'\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94644ee6-bb03-4a02-b763-5333cac57a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def log(self, logs: Dict[str, float]) -> None:\n",
    "        logs[\"learning_rate\"] = self._get_learning_rate()\n",
    "        super().log(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbc9637f-1f80-4540-86d0-269a54ebf788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = MyTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca287969-065a-4703-aa9e-ec529bbacfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4800' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4800/4800 15:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.457138</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.515300</td>\n",
       "      <td>0.464598</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.471932</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.608199</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.668092</td>\n",
       "      <td>0.657500</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.799083</td>\n",
       "      <td>0.663333</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.875607</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>1.088807</td>\n",
       "      <td>0.621667</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.149400</td>\n",
       "      <td>1.055743</td>\n",
       "      <td>0.664167</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>1.073924</td>\n",
       "      <td>0.664167</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4800, training_loss=0.2686312572161357, metrics={'train_runtime': 948.271, 'train_samples_per_second': 50.618, 'train_steps_per_second': 5.062, 'total_flos': 3157361012736000.0, 'train_loss': 0.2686312572161357, 'learning_rate': 2e-05, 'epoch': 10.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502352a2-8271-4cb3-b320-e94c72408012",
   "metadata": {},
   "source": [
    "# Train Model Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d7b0d82-1338-4fee-8514-19b2ae5d6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "metric_name = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f524592b-87b5-4d59-8488-d43031e95e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = AutoModelForSequenceClassification.from_pretrained('roberto-round-1/checkpoint-4800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db344a4-cc3b-49ba-9c27-1be7345fc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args2 = TrainingArguments(\n",
    "    f\"roberto-round-2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-6, # 2e-5\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    # weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    warmup_steps= 100,\n",
    "    lr_scheduler_type= 'constant'\n",
    "    #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd5ae1f1-686a-497e-9073-dcca15ef9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(\n",
    "    model2,\n",
    "    args2,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f68deaa9-f2d6-49f1-bef4-51e7bbd7d9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2881' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2881/4800 09:06 < 06:04, 5.27 it/s, Epoch 6/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.173095</td>\n",
       "      <td>0.655833</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>1.202227</td>\n",
       "      <td>0.660833</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>1.249877</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>1.213973</td>\n",
       "      <td>0.664167</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>1.269762</td>\n",
       "      <td>0.655833</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>1.279936</td>\n",
       "      <td>0.660833</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41437429-1723-46b4-b6a3-90b0e7b16c55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7b1df-05b1-4208-a831-568c7bbdd86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save_pretrained('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74dff90f-b88e-44b7-95c9-79f955a2b7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7568681240081787,\n",
       " 'eval_f1': 0.6399331662489557,\n",
       " 'eval_roc_auc': 0.7299999999999999,\n",
       " 'eval_accuracy': 0.635}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7157b-ac45-4633-99dc-a3a755e288df",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e1ad3b6-1819-4b24-820f-c3d48979aec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\nDuring my recent company trip to our Tempe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nAfter hearing about Pauly D from Jersey Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n\\nI had high hopes for this restaurant based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We experienced overpriced and underwhelming en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n\\nThe windows from this company are definite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               text\n",
       "0   1  \\n\\nDuring my recent company trip to our Tempe...\n",
       "1   2  \\n\\nAfter hearing about Pauly D from Jersey Sh...\n",
       "2   3  \\n\\nI had high hopes for this restaurant based...\n",
       "3   4  We experienced overpriced and underwhelming en...\n",
       "4   5  \\n\\nThe windows from this company are definite..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cb1338b-8e44-4053-9e01-a90006b17d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = 'roberta_base_v10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59412f3f-6eac-4512-ba5c-07fcb33a34ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "error_ind = []\n",
    "with open(output_path, \"w\", newline='') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"ID\",\"Label\"])\n",
    "    for index, row in test_data.iterrows():\n",
    "        text_id = row['ID']\n",
    "        text = row['text']\n",
    "        encoding = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
    "        # print(encoding)\n",
    "        # print(encoding['attention_mask'].size())\n",
    "        try:\n",
    "            outputs = trainer.model(**encoding)\n",
    "        except: \n",
    "            count += 1\n",
    "            error_ind.append(text_id)\n",
    "        logits = outputs.logits\n",
    "        # apply sigmoid + threshold\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(logits.squeeze().cpu())\n",
    "        predictions = np.zeros(probs.shape)\n",
    "        predictions[np.argmax(probs.detach().numpy())] = 1\n",
    "        # turn predicted id's into actual label names\n",
    "        predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
    "        \n",
    "        if predicted_labels[0] == 'one_star':\n",
    "            conv_pred = 1\n",
    "        elif predicted_labels[0] == 'two_stars':\n",
    "            conv_pred = 2\n",
    "        else: \n",
    "            conv_pred = 3\n",
    "\n",
    "        \n",
    "        csv_writer.writerow([text_id,conv_pred])\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530e8a4-aaec-40f9-afde-ae0c8ff5dad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
