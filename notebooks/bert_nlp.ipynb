{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ba65e3-f3bb-4b56-8872-c4ad3ff8cf4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4707758-c9c9-4260-80fa-cfe5d9d47f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv transformers==4.38.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c826c0c-2943-41d7-9fa4-467a82a59c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv datasets==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32fc46f-177b-4938-9d88-ac039167ba10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d207cd-8326-43f1-94f6-6d36d16da018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv keras==3.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecebd6d0-e0e1-4fc8-bcf8-72d2a4041741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9933b9ab-226a-49db-b1a4-239a4d882638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv nltk==3.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190bd2b6-519c-4be6-89b1-807d9047c8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv contractions==0.1.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbca02f5-f674-4b70-82dd-bb38567eac81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -Iv accelerate==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "758e973f-ccfb-4a53-ab93-a01784b8cfcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-03-10 17:37:44.893191: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-10 17:37:45.741773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, load_dataset, load_metric\n",
    "import datasets\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding, DistilBertConfig, DistilBertForSequenceClassification, BertConfig, BertForSequenceClassification, create_optimizer, TrainingArguments, Trainer\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import pipeline\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e15d91-ef49-4c15-935c-076bf7ca698f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8751bfa4-2c0b-4241-8bb8-b97279565749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = 'data/train.csv'\n",
    "test_data_path = 'data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe48ba27-0e35-4662-9775-060001a02db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILL NEVER COME BACK! HORRIBLE SERVICE &amp; NASTY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible food.  Terrible service.\\n\\nThe absol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So, right away if I go into a buffet setting, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have gotten good cuts from this place. I eve...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I felt this place was a bit lackluster conside...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  WILL NEVER COME BACK! HORRIBLE SERVICE & NASTY...      1\n",
       "1  Terrible food.  Terrible service.\\n\\nThe absol...      1\n",
       "2  So, right away if I go into a buffet setting, ...      2\n",
       "3  I have gotten good cuts from this place. I eve...      3\n",
       "4  I felt this place was a bit lackluster conside...      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data = pd.read_csv(train_data_path)\n",
    "labelled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5220cd1d-8170-4f0e-b85e-f852a0c50f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelled_data['stars'] = labelled_data['stars'].replace({1: 0, 2: 1, 3: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fdd68cf-a963-4152-afb1-94e59f797be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WILL NEVER COME BACK! HORRIBLE SERVICE &amp; NASTY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible food.  Terrible service.\\n\\nThe absol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So, right away if I go into a buffet setting, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have gotten good cuts from this place. I eve...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I felt this place was a bit lackluster conside...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  WILL NEVER COME BACK! HORRIBLE SERVICE & NASTY...      0\n",
       "1  Terrible food.  Terrible service.\\n\\nThe absol...      0\n",
       "2  So, right away if I go into a buffet setting, ...      1\n",
       "3  I have gotten good cuts from this place. I eve...      2\n",
       "4  I felt this place was a bit lackluster conside...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635b2c15-b336-4f75-b7ca-ad54e3cae706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 1. Expand Contractions using contractions library\n",
    "# def expand_contractions(text):\n",
    "#     return contractions.fix(text)\n",
    "\n",
    "# # Apply expand_contractions function to 'text' column\n",
    "# labelled_data['text'] = labelled_data['text'].apply(expand_contractions)\n",
    "\n",
    "# # 2. Lower Case\n",
    "# labelled_data['text'] = labelled_data['text'].str.lower()\n",
    "\n",
    "# # 3. Remove Punctuations\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# # 4. Remove Extra Spaces\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda x: re.sub(' +', ' ', x.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d3075a-a13b-4f3b-b235-e46a7fb37aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download the WordNet resource\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "870227d5-4752-4a64-b8af-575cdb0d7ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 5. Remove Stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb937415-a715-46b8-891e-dfa040bf22dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download the WordNet resource\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56e743eb-301c-4d39-ad4b-5f308fe22fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip /home/ec2-user/nltk_data/corpora/wordnet.zip -d /home/ec2-user/nltk_data/corpora/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "261ab0ae-371b-44ee-8693-5364e797e647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 6. Stemming and Lemmatization\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# def lemmatize_words(text):\n",
    "#     return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "# labelled_data['text'] = labelled_data['text'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f803d682-0f1d-44e9-a6bb-78356e51285c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labelled_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01886e06-9be0-4441-a338-c2d953c65e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    labelled_data['text'], \n",
    "    labelled_data['stars'], \n",
    "    test_size= 0.2, \n",
    "    random_state= 42, \n",
    "    stratify= labelled_data['stars']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13cff12f-028b-4840-90e1-fd090ca82fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stars\n",
      "2    1600\n",
      "1    1600\n",
      "0    1600\n",
      "Name: count, dtype: int64\n",
      "stars\n",
      "0    400\n",
      "2    400\n",
      "1    400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_valid.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0463147-4173-42ee-b13e-81491c1f0e14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "train_ind = X_train.index.values.tolist()\n",
    "valid_ind = X_valid.index.values.tolist()\n",
    "\n",
    "train_data = {'text': [], 'label': []}\n",
    "valid_data = {'text': [], 'label': []}\n",
    "\n",
    "for ti in train_ind:\n",
    "    train_data['text'].append(X_train[ti])\n",
    "    train_data['label'].append(y_train[ti])\n",
    "\n",
    "for vi in valid_ind:\n",
    "    valid_data['text'].append(X_valid[vi])\n",
    "    valid_data['label'].append(y_valid[vi])\n",
    "    \n",
    "print(len(train_data['text']))\n",
    "print(len(valid_data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "821db20f-0478-4d9f-8acb-cfc838adf6aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict(train_data)\n",
    "valid_dataset = Dataset.from_dict(valid_data)\n",
    "data = datasets.DatasetDict({\"train\": train_dataset,\"valid\": valid_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0601ffdd-49af-4e7a-8c60-dabdcd91b7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b994731-ad04-453c-a258-2c1bee196655",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aa05bba-430c-4cb9-b93f-d0a23f4bd48c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c19d89162a4f9fad1a1f4332e59d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a9f732c8f646ef887598caadc07753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e24490199c4ba9b58bcf8562ec4b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9a39a70d7c454588ca8b3a1131b861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "445d7735-b1b0-4d61-a666-c55f816f20d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function preprocess_function at 0x7fe1d98d0670> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52500ef79804e6fa8e360087db43dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fea3e5b387418bb11d0138c2b28826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36d745c4-5223-40ed-80fb-d6d2a73f7ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 4800\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f83c00b-3afe-40c9-9222-13c413a0aaad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ccc166-6765-42b8-90dc-e3b67232407a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9ee71-459f-4653-a2b1-c9377ab2eb9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e30edf74-874c-4b4c-a491-c0d68d5b50e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"OneStar\", 1: \"TwoStar\", 2: \"ThreeStar\"}\n",
    "label2id = {\"OneStar\": 0, \"TwoStar\": 1, \"ThreeStar\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd9be9bd-1cc2-45ae-833e-b02d6040b332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640afee68c1b496ea01cba3b101c1e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- distilbert.embeddings.position_embeddings.weight: found shape torch.Size([512, 768]) in the checkpoint and torch.Size([1024, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# config = DistilBertConfig(num_labels= 3, max_position_embeddings= 1024, id2label=id2label, label2id=label2id) # You can also change the architecture using this config class\n",
    "\n",
    "# model = DistilBertForSequenceClassification(config=config)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id, max_position_embeddings= 1024, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efd53ef9-3a92-4a4b-b7f4-a733c4dbade6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e774d9cb-5d67-417f-92fb-3c868435ffc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 5\n",
    "# batches_per_epoch = len(tokenized_data[\"train\"]) // batch_size\n",
    "# total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "# optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70132ca4-4734-460d-8fb6-c55de90f40a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    lr_scheduler_type= \"linear\",\n",
    "    warmup_steps= 500,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.001,\n",
    "    metric_for_best_model=metric_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24fe3076-1618-49ef-a181-502ce90d83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211dc9e9ee2946e6999614276a423e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbc9637f-1f80-4540-86d0-269a54ebf788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"valid\"],\n",
    "    data_collator= data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7f671-413a-4afe-937d-ddcfc90cfa9b",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca287969-065a-4703-aa9e-ec529bbacfc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2975' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2975/4500 3:42:33 < 1:54:09, 0.22 it/s, Epoch 9.91/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.842632</td>\n",
       "      <td>0.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.901500</td>\n",
       "      <td>0.846545</td>\n",
       "      <td>0.584167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.901500</td>\n",
       "      <td>0.845185</td>\n",
       "      <td>0.598333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.968465</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>1.372641</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.396500</td>\n",
       "      <td>1.678784</td>\n",
       "      <td>0.590833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>1.871284</td>\n",
       "      <td>0.595833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>2.359342</td>\n",
       "      <td>0.580833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>2.253268</td>\n",
       "      <td>0.605833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory distilbert-base-uncased-finetuned/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory distilbert-base-uncased-finetuned/checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory distilbert-base-uncased-finetuned/checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41437429-1723-46b4-b6a3-90b0e7b16c55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7b1df-05b1-4208-a831-568c7bbdd86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d7157b-ac45-4633-99dc-a3a755e288df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e1ad3b6-1819-4b24-820f-c3d48979aec5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\nDuring my recent company trip to our Tempe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\nAfter hearing about Pauly D from Jersey Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n\\nI had high hopes for this restaurant based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We experienced overpriced and underwhelming en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n\\nThe windows from this company are definite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               text\n",
       "0   1  \\n\\nDuring my recent company trip to our Tempe...\n",
       "1   2  \\n\\nAfter hearing about Pauly D from Jersey Sh...\n",
       "2   3  \\n\\nI had high hopes for this restaurant based...\n",
       "3   4  We experienced overpriced and underwhelming en...\n",
       "4   5  \\n\\nThe windows from this company are definite..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_data_path)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6cb1338b-8e44-4053-9e01-a90006b17d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = 'outputs/distil_bert_v04.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59412f3f-6eac-4512-ba5c-07fcb33a34ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(output_path, \"w\", newline='') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "    csv_writer.writerow([\"ID\",\"Label\"])\n",
    "    for index, row in test_data.iterrows():\n",
    "        text_id = row['ID']\n",
    "        text = row['text']\n",
    "        inputs_id = tokenizer.encode(text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs_id)\n",
    "        # Get the predicted probabilities\n",
    "        probs = torch.softmax(outputs.logits, dim=1).squeeze()\n",
    "\n",
    "        # Convert probabilities to labels\n",
    "        predicted_label = torch.argmax(probs).item()\n",
    "        \n",
    "        if predicted_label == 0: \n",
    "            conv_pred = 1\n",
    "        elif predicted_label == 1:\n",
    "            conv_pred = 2\n",
    "        else: \n",
    "            conv_pred = 3\n",
    "        \n",
    "        csv_writer.writerow([text_id,conv_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65a1825-5b72-4954-b6d4-9a47558f1f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
